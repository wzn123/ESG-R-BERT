{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acknowledge\n",
    "# This is a Group project with ZhiWei Zhan, Boyangzhang, Jiayou Qu. The pulished code may have very similar content with their published code.\n",
    "# Some codes are inspired by open source project and ChatGPT\n",
    "# the model RNN, LSTM, GRU are reference from pytorch official website https://pytorch.org/\n",
    "\n",
    "# This step 3 code has done:\n",
    "# 1, train the mapping model with step 3 data and make prdiction\n",
    "# 2, test the mapping model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "#import package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data as ds\n",
    "from model import RNN,LSTM,GRU\n",
    "import torch.nn.functional as F\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression dataset\n",
    "class MyDataset1(ds.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.samples = X\n",
    "        self.labels = Y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.samples[index]\n",
    "        label = [self.labels[index]]\n",
    "        #print(label)\n",
    "        sample=torch.Tensor(sample).float()\n",
    "        label= torch.Tensor(label).float()\n",
    "\n",
    "        return sample, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load step 3 report representation data\n",
    "report_repre=pd.read_csv('D:/UCL/workspace/final/ESGOverallData.csv')\n",
    "report_repre.dropna(inplace=True)\n",
    "sorted_df = report_repre.sort_values(by='Year')\n",
    "filtered_df = sorted_df[sorted_df['BloombergOverall'] != 0]\n",
    "report_repre=filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CompanyTicker</th>\n",
       "      <th>Year</th>\n",
       "      <th>CSV.Length</th>\n",
       "      <th>ESGData</th>\n",
       "      <th>BloombergOverall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>285</td>\n",
       "      <td>GEN</td>\n",
       "      <td>2015</td>\n",
       "      <td>438</td>\n",
       "      <td>[[0.0055219298228621, 0.0078070522285997, 0.00...</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>488</td>\n",
       "      <td>QLYS</td>\n",
       "      <td>2015</td>\n",
       "      <td>262</td>\n",
       "      <td>[[0.0129457972943782, 0.0162092745304107, 0.01...</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>191</td>\n",
       "      <td>EFX</td>\n",
       "      <td>2015</td>\n",
       "      <td>1044</td>\n",
       "      <td>[[0.0027446697931736, 0.0058759758248925, 0.00...</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>ANSS</td>\n",
       "      <td>2015</td>\n",
       "      <td>837</td>\n",
       "      <td>[[0.0023921008687466, 0.0108177633956074, 0.00...</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>QTWO</td>\n",
       "      <td>2015</td>\n",
       "      <td>1245</td>\n",
       "      <td>[[0.0087282583117485, 0.0131738986819982, 0.00...</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>HUBS</td>\n",
       "      <td>2022</td>\n",
       "      <td>1297</td>\n",
       "      <td>[[0.0087282583117485, 0.0131738986819982, 0.00...</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>291</td>\n",
       "      <td>GEN</td>\n",
       "      <td>2022</td>\n",
       "      <td>785</td>\n",
       "      <td>[[0.0055219298228621, 0.0078070522285997, 0.00...</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>474</td>\n",
       "      <td>PRO</td>\n",
       "      <td>2022</td>\n",
       "      <td>273</td>\n",
       "      <td>[[0.0129457972943782, 0.0162092745304107, 0.01...</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>464</td>\n",
       "      <td>PCTY</td>\n",
       "      <td>2022</td>\n",
       "      <td>789</td>\n",
       "      <td>[[0.0032370127737522, 0.0083294827491045, 0.00...</td>\n",
       "      <td>2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>563</td>\n",
       "      <td>SPSC</td>\n",
       "      <td>2022</td>\n",
       "      <td>140</td>\n",
       "      <td>[[0.0129457972943782, 0.0162092745304107, 0.01...</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 CompanyTicker  Year  CSV.Length  \\\n",
       "285         285           GEN  2015         438   \n",
       "488         488          QLYS  2015         262   \n",
       "191         191           EFX  2015        1044   \n",
       "57           57          ANSS  2015         837   \n",
       "496         496          QTWO  2015        1245   \n",
       "..          ...           ...   ...         ...   \n",
       "306         306          HUBS  2022        1297   \n",
       "291         291           GEN  2022         785   \n",
       "474         474           PRO  2022         273   \n",
       "464         464          PCTY  2022         789   \n",
       "563         563          SPSC  2022         140   \n",
       "\n",
       "                                               ESGData  BloombergOverall  \n",
       "285  [[0.0055219298228621, 0.0078070522285997, 0.00...              3.31  \n",
       "488  [[0.0129457972943782, 0.0162092745304107, 0.01...              1.70  \n",
       "191  [[0.0027446697931736, 0.0058759758248925, 0.00...              1.66  \n",
       "57   [[0.0023921008687466, 0.0108177633956074, 0.00...              1.48  \n",
       "496  [[0.0087282583117485, 0.0131738986819982, 0.00...              1.33  \n",
       "..                                                 ...               ...  \n",
       "306  [[0.0087282583117485, 0.0131738986819982, 0.00...              3.66  \n",
       "291  [[0.0055219298228621, 0.0078070522285997, 0.00...              4.69  \n",
       "474  [[0.0129457972943782, 0.0162092745304107, 0.01...              2.97  \n",
       "464  [[0.0032370127737522, 0.0083294827491045, 0.00...              2.21  \n",
       "563  [[0.0129457972943782, 0.0162092745304107, 0.01...              1.91  \n",
       "\n",
       "[421 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_repre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    x_train=[]\n",
    "    y_train=[]\n",
    "    for index,row in df.iterrows():\n",
    "        x_train.append(ast.literal_eval(row[\"ESGData\"]))\n",
    "        y_train.append(float(row[\"BloombergOverall\"]))\n",
    "    y_train=scaler.fit_transform(np.array(y_train).reshape(-1,1))\n",
    "    return x_train,y_train\n",
    "x,y=generate_data(report_repre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add padding for too short samples and trim too long samples\n",
    "def pad_time_series(data, target_length=None, padding_value=0.0):\n",
    "    # Determine the target length if not provided\n",
    "    final_result=[]\n",
    "    if target_length is None:\n",
    "        target_length = max(len(sample) for sample in data)\n",
    "\n",
    "    for sample in data:\n",
    "        if len(sample) < target_length:\n",
    "            for _ in range(target_length - len(sample)):\n",
    "                sample.append([padding_value for _ in range(4)])\n",
    "            final_result.append(sample)\n",
    "        \n",
    "        elif len(sample) > target_length:\n",
    "            fourth_values = [item[3] for item in sample]\n",
    "            indices_to_keep = sorted(range(len(fourth_values)), key=lambda i: fourth_values[i], reverse=False)[:target_length]\n",
    "            trimmed_report = [sample[i] for i in sorted(indices_to_keep)]\n",
    "            final_result.append(trimmed_report)\n",
    "        \n",
    "        else:\n",
    "            final_result.append(sample)\n",
    "\n",
    "    return final_result\n",
    "            \n",
    "x = pad_time_series(x, 500, padding_value=0.25)\n",
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "def loop(model,train_loader,test_loader,optimizer,criterion,device,E=20):\n",
    "    loss_all=[]\n",
    "    result_all=[]\n",
    "    for epoch in range(E): \n",
    "        loss_epoch=[]\n",
    "        print(epoch)\n",
    "        for samples, labels in train_loader:\n",
    "            samples=samples.to(device)\n",
    "            labels=labels.to(device)\n",
    "            #print(samples.shape)\n",
    "            #print(labels.shape)\n",
    "        # Set the flag to training mode\n",
    "            model.train()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(samples)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_epoch.append(float(loss.cpu()))\n",
    "            #print(outputs)\n",
    "        print(sum(loss_epoch)/len(loss_epoch))\n",
    "        loss_all.append(sum(loss_epoch)/len(loss_epoch))\n",
    "\n",
    "        # evaulate the model in every epoch\n",
    "        model.eval()\n",
    "        result=[]\n",
    "        true_a=[]\n",
    "        test_loss=0\n",
    "        for samples, true in test_loader:\n",
    "            samples=samples.to(device)\n",
    "            outputs = model(samples)\n",
    "            test = criterion(outputs.squeeze(), true.to(device))\n",
    "            test_loss += test.item()\n",
    "            result.append(float(outputs.cpu()))\n",
    "            true_a.append(float(true.cpu()))\n",
    "        \n",
    "        test_loss /= len(test_loader)\n",
    "        ic, _ = pearsonr(result, true_a)\n",
    "        rank_ic, _ = spearmanr(result, true_a)\n",
    "        result_all.append(result)\n",
    "        print('test loss:', test_loss, 'pearson:', ic, 'spearman:', rank_ic)\n",
    "\n",
    "    return result,loss_epoch,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train and test set\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "batch_size=64\n",
    "learning_rate=0.01\n",
    "epoch=50\n",
    "hidden_num=256\n",
    "output_dim=1 #if None put ''\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dataset\n",
    "train_dataset = MyDataset1(train_x,train_y)\n",
    "test_dataset = MyDataset1(test_x,test_y)\n",
    "train_loader=ds.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader=ds.DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test the model\n",
    "features_dim=np.array(x).shape[2]\n",
    "modelRNN=GRU.GRU_Model(features_dim,hidden_num,output_dim).to(device)\n",
    "optimizerRNN= optim.Adam(modelRNN.parameters(), lr=learning_rate)\n",
    "resultRNN,lossRNN,modelRNN=loop(modelRNN,train_loader,test_loader,optimizerRNN,criterion,device,E=epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
